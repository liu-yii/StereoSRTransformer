{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取相机参数\n",
    "def read_calib(calib_file_path):\n",
    "    with open(calib_file_path, 'r') as calib_file:\n",
    "        calib = {}\n",
    "        csv_reader = csv.reader(calib_file, delimiter='=')\n",
    "        for attr, value in csv_reader:\n",
    "            calib.setdefault(attr, value)\n",
    "    return calib\n",
    "\n",
    "def read_pfm(pfm_file_path):\n",
    "    with open(pfm_file_path, 'rb') as pfm_file:\n",
    "        header = pfm_file.readline().decode().rstrip()\n",
    "        channels = 3 if header == 'PF' else 1\n",
    "        dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', pfm_file.readline().decode('utf-8'))\n",
    "        if dim_match:\n",
    "            width, height = map(int, dim_match.groups())\n",
    "        else:\n",
    "            raise Exception(\"Malformed PFM header.\")\n",
    "\n",
    "        scale = float(pfm_file.readline().decode().rstrip())\n",
    "        if scale < 0:\n",
    "            endian = '<'  # littel endian\n",
    "            scale = -scale\n",
    "        else:\n",
    "            endian = '>'  # big endian\n",
    "\n",
    "        dispariy = np.fromfile(pfm_file, endian + 'f')\n",
    "\n",
    "    img = np.reshape(dispariy, newshape=(height, width, channels))\n",
    "    img = np.flipud(img).astype('uint8')\n",
    "    print(img.max(), img.min())\n",
    "    # cv2.imshow(\"disparity\", img)\n",
    "    return dispariy, [(height, width, channels), scale]\n",
    "\n",
    "def create_depth_map(pfm_file_path, calib=None):\n",
    "    dispariy, [shape, scale] = read_pfm(pfm_file_path)\n",
    "\n",
    "    if calib is None:\n",
    "        raise Exception(\"Loss calibration information.\")\n",
    "    else:\n",
    "        fx = float(calib['cam0'].split(' ')[0].lstrip('['))\n",
    "        base_line = float(calib['baseline'])\n",
    "        doffs = float(calib['doffs'])\n",
    "        # scale factor is used here\n",
    "        # d = bf/(d+ doffs)         doffs就是(x_or-x_ol) 两个相机主点在各自图像坐标系x方向上的坐标差\n",
    "        depth_map = fx * base_line / (dispariy / scale + doffs)\n",
    "        depth_map = np.reshape(depth_map, newshape=shape)\n",
    "        depth_map = np.flipud(depth_map).astype('uint8')\n",
    "        return depth_map\n",
    "\n",
    "# def show(img, win_name='image'):\n",
    "#     if img is None:\n",
    "#         raise Exception(\"Can't display an empty image.\")\n",
    "#     else:\n",
    "#         # cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n",
    "#         cv2.imshow(win_name, img)\n",
    "#         cv2.waitKey()\n",
    "#         cv2.destroyWindow(win_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1924, 2960])\n",
      "torch.Size([1, 5695040, 2]) torch.Size([1, 5695040, 3])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import to_pixel_samples, make_coord, warp_coord\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# 加载左图像和视差图\n",
    "left_img = transforms.ToTensor()(cv2.imread('demo\\Pipes-perfect\\im0.png')).unsqueeze(0)\n",
    "right_img = transforms.ToTensor()(cv2.imread('demo\\Pipes-perfect\\im1.png')).unsqueeze(0)\n",
    "print(left_img.shape)\n",
    "_,c,h,w = left_img.shape\n",
    "hr_coord, hrl_rgb = to_pixel_samples(left_img.contiguous())\n",
    "_, hrr_rgb = to_pixel_samples(right_img.contiguous())\n",
    "sample_lst = np.random.choice(\n",
    "                len(hr_coord), 2304, replace=False)\n",
    "hr_coord = hr_coord.unsqueeze(0)\n",
    "hrl_rgb = hrl_rgb.unsqueeze(0)\n",
    "hrr_rgb = hrr_rgb.unsqueeze(0)\n",
    "print(hr_coord.shape, hrl_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 0\n",
      "[149.93364 149.91214 149.88821 ... 116.0108  115.87364 115.84978]\n",
      "(1924, 2960, 1)\n",
      "255 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_46592\\3867768275.py:30: RuntimeWarning: invalid value encountered in cast\n",
      "  img = np.flipud(img).astype('uint8')\n"
     ]
    }
   ],
   "source": [
    "pfm_file_dir = Path('demo/Pipes-perfect')\n",
    "calib_file_path = pfm_file_dir.joinpath('calib.txt')\n",
    "disp_left = pfm_file_dir.joinpath('disp1.pfm')\n",
    "disparity, [shape, scale] = read_pfm(disp_left)\n",
    "print(disparity)\n",
    "disparity = np.reshape(disparity, newshape=shape)\n",
    "disparity = np.flipud(disparity)\n",
    "print(disparity.shape)\n",
    "# calibration information\n",
    "calib = read_calib(calib_file_path)\n",
    "# create depth map\n",
    "depth_map_left = create_depth_map(disp_left, calib)\n",
    "# show(depth_map_left, \"depth_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'remap'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m x_map \u001b[38;5;241m=\u001b[39m x_map \u001b[38;5;241m-\u001b[39m disparity[:,:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 使用remap函数进行warp\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m warped_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTER_LINEAR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mborderMode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBORDER_CONSTANT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 保存结果\u001b[39;00m\n\u001b[0;32m     13\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvis/warped.png\u001b[39m\u001b[38;5;124m'\u001b[39m, warped_img)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'remap'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "# 创建x和y映射\n",
    "height, width, _ = disparity.shape\n",
    "x_map = np.float32(np.tile(np.linspace(0, width-1, width), (height, 1)))\n",
    "y_map = np.float32(np.tile(np.linspace(0, height-1, height), (width, 1)).T)\n",
    "\n",
    "# 考虑到视差，更新x映射\n",
    "x_map = x_map - disparity[:,:,0]\n",
    "\n",
    "# 使用remap函数进行warp\n",
    "warped_img = cv2.remap(left_img, x_map, y_map, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "# 保存结果\n",
    "cv2.imwrite('vis/warped.png', warped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1924, 2960, 1)\n",
      "tensor([[[-0.0078, -0.0157,  0.0157],\n",
      "         [-0.0039, -0.0157,  0.0039],\n",
      "         [-0.0078, -0.0196, -0.0039],\n",
      "         ...,\n",
      "         [-0.0353, -0.0235, -0.0235],\n",
      "         [-0.0353, -0.0275, -0.0275],\n",
      "         [-0.0353, -0.0275, -0.0275]]])\n",
      "tensor(0.0268)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# disparity = cv2.imread('vis/out_disp.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# disparity = np.expand_dims(disparity, -1)\n",
    "print(disparity.shape)\n",
    "disparity_new = transforms.ToTensor()(disparity.copy())\n",
    "hrl_d = disparity_new.view(1, -1).permute(1, 0)\n",
    "hrl_d = hrl_d.unsqueeze(0)\n",
    "\n",
    "# left_warp = warp_coord(hr_coord, hrl_d, right_img)\n",
    "right_warp = warp_coord(hr_coord, hrl_d, left_img, mode='l2r')\n",
    "# left_warp = left_warp.permute(0, 2, 1).contiguous()\n",
    "\n",
    "# diff = left_warp - hrl_rgb\n",
    "diff = right_warp - hrr_rgb\n",
    "\n",
    "print(diff)\n",
    "# vis\n",
    "# left_warp = left_warp * 255.\n",
    "# left_warp = left_warp.view(1, h, w, 3).squeeze(0).permute(2, 0, 1).contiguous().numpy().astype(np.uint8).transpose(1,2,0)\n",
    "# cv2.imwrite('vis/warped_new.png', left_warp)\n",
    "\n",
    "right_warp = right_warp * 255.\n",
    "right_warp = right_warp.view(1, h, w, 3).squeeze(0).permute(2, 0, 1).contiguous().numpy().astype(np.uint8).transpose(1,2,0)\n",
    "cv2.imwrite('vis/warped_new1.png', right_warp)\n",
    "\n",
    "diff = diff.view(1, h, w, 3).squeeze(0).permute(2, 0, 1).contiguous()\n",
    "print(diff.mean())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warp\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m img_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_tensor\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_tensor\u001b[38;5;241m.\u001b[39mtype())\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "from utils import warp\n",
    "import torch\n",
    "img_tensor = torch.from_numpy(np.expand_dims(left_img, 0).transpose(0, 3, 1, 2)).float()\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor.type())\n",
    "disparity_tensor = torch.from_numpy(disparity.copy()).unsqueeze(0).permute(0, 3, 1, 2).float()\n",
    "print(disparity_tensor.type())\n",
    "print(disparity_tensor)\n",
    "warped_img_new = warp(img_tensor, disparity_tensor, mode='r2l')\n",
    "warped_img_new = warped_img_new.view(1,img_tensor.shape[2],img_tensor.shape[3],-1).permute(0,3,1,2).squeeze(0).numpy().astype(np.uint8).transpose(1,2,0)\n",
    "print(warped_img_new.shape)\n",
    "# 保存结果\n",
    "cv2.imwrite('vis/warped_new.png', warped_img_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0495, 0.1418, 0.3764, 0.2652],\n",
      "          [0.4315, 0.6114, 0.6444, 0.8426],\n",
      "          [0.7846, 0.6737, 0.1217, 0.9667]],\n",
      "\n",
      "         [[0.0181, 0.0375, 0.1108, 0.6531],\n",
      "          [0.4091, 0.0390, 0.0898, 0.2533],\n",
      "          [0.3682, 0.1509, 0.7292, 0.1315]]]])\n",
      "tensor([[[0.0495, 0.1418],\n",
      "         [0.3764, 0.2652],\n",
      "         [0.4315, 0.6114],\n",
      "         [0.6444, 0.8426]],\n",
      "\n",
      "        [[0.7846, 0.6737],\n",
      "         [0.1217, 0.9667],\n",
      "         [0.0181, 0.0375],\n",
      "         [0.1108, 0.6531]],\n",
      "\n",
      "        [[0.4091, 0.0390],\n",
      "         [0.0898, 0.2533],\n",
      "         [0.3682, 0.1509],\n",
      "         [0.7292, 0.1315]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand([1,2,3,4])\n",
    "print(a)\n",
    "a2 = a.contiguous().reshape(3,4,2)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
